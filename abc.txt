
import pandas as pd
import numpy as np
import matplotlib as plt
#Reading the dataset in a dataframe using Pandas
df = pd.read_csv("data/train_LoanPredDataset.csv") 
df.head(10)
df.types
df.describe()
df.shape
df['Property_Area'].value_counts()
df['Education'].value_counts()
%matplotlib inline
df['ApplicantIncome'].hist(bins=50);
df.boxplot(column='ApplicantIncome');
df['LoanAmount'].hist(bins=50);
df.boxplot(column='LoanAmount');
//categorical variable analysis
temp1 = df['Credit_History'].value_counts(ascending=True)
print('Frequency Table for Credit History:')
print(temp1)
temp2 = df.pivot_table(values='Loan_Status',index=['Credit_History'],
                       aggfunc=lambda x: x.map({'Y':1,'N':0}).mean())
print('Probility of getting loan for each Credit History class:')
print(temp2)
import matplotlib.pyplot as plt
fig = plt.figure(figsize=(8,4))
ax1 = fig.add_subplot(121);
ax1.set_xlabel('Credit_History');
ax1.set_ylabel('Count of Applicants');
ax1.set_title("Applicants by Credit_History");
temp1.plot(kind='bar');

ax2 = fig.add_subplot(122);
temp2.plot(kind = 'bar');
ax2.set_xlabel('Credit_History');
ax2.set_ylabel('Probability of getting loan');
ax2.set_title("Probability of getting loan by credit history");
temp3 = pd.crosstab(df['Credit_History'], df['Loan_Status'])
temp3.plot(kind='bar', stacked=True, color=['red','blue'], grid=False);
temp3 = pd.crosstab([df['Credit_History'],df['Gender']], df['Loan_Status'])
temp3.plot(kind='bar', stacked=True, color=['red','blue'], grid=False);
df.apply(lambda x: sum(x.isnull()),axis=0) 
import seaborn as sns
sns.set_style("whitegrid")
ax = sns.boxplot(x="Self_Employed", y="LoanAmount", hue="Education", data=df, palette="Set3")
df['Self_Employed'].value_counts() 
df['Self_Employed'].fillna('No',inplace=True) 
table = df.pivot_table(values='LoanAmount', 
index='Self_Employed' ,columns='Education', aggfunc=np.median)
table
# Define function to return value of this pivot_table
def fage(x):
    return table.loc[x['Self_Employed'],x['Education']]
# Replace missing values
df['LoanAmount'].fillna(df[df['LoanAmount'].isnull()].apply(fage, axis=1), inplace=True) 
df.apply(lambda x: sum(x.isnull()),axis=0) 
df['LoanAmount_log'] = np.log(df['LoanAmount'])

df['LoanAmount_log'].hist(bins=20);
df['TotalIncome'] = df['ApplicantIncome'] + df['CoapplicantIncome']
df['TotalIncome_log'] = np.log(df['TotalIncome'])
df['LoanAmount_log'].hist(bins=20);
df.apply(lambda x: sum(x.isnull()),axis=0) 
df['Gender'].value_counts()
df['Gender'].fillna('Male',inplace=True)
df['Married'].value_counts()
df['Married'].fillna('Yes',inplace=True)
df['Dependents'].value_counts()
df['Dependents'].fillna('0',inplace=True)
df['Loan_Amount_Term'].value_counts()
df['Loan_Amount_Term'].fillna(df['Loan_Amount_Term'].mean(), inplace=True)
df['Credit_History'].value_counts()
df['Credit_History'].fillna(1.0,inplace=True)
//categorical to numeric using LabelEncoder as sklearn takes only numeric variables
from sklearn.preprocessing import LabelEncoder
var_mod = ['Gender','Married','Dependents','Education',
           'Self_Employed','Property_Area','Loan_Status']
le = LabelEncoder()
for i in var_mod:
    df[i] = le.fit_transform(df[i])
df.dtypes 
from sklearn.linear_model import LogisticRegression
from sklearn.cross_validation import KFold   #For K-fold cross validation
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier, export_graphviz
from sklearn import metrics

#Generic function for making a classification model and assessing performance
def classification_model(model, data, predictors, outcome):
  #Fit the model:
  model.fit(data[predictors],data[outcome])
  #Make predictions on training set:
  predictions = model.predict(data[predictors])
  #Print accuracy
  accuracy = metrics.accuracy_score(predictions,data[outcome])
  print("Accuracy : %s" % "{0:.3%}".format(accuracy))
  #Perform k-fold cross-validation with 5 folds
  kf = KFold(data.shape[0], n_folds=5)
  error = []
  for train, test in kf:
    # Filter training data
    train_predictors = (data[predictors].iloc[train,:])
    # The target we're using to train the algorithm.
    train_target = data[outcome].iloc[train]
    # Training the algorithm using the predictors and target.
    model.fit(train_predictors, train_target)
    #Record error from each cross-validation run
    error.append(model.score(data[predictors].iloc[test,:], data[outcome].iloc[test]))
  print("Cross-Validation Score : %s" % "{0:.3%}".format(np.mean(error)))
  #Fit the model again so that it can be refered outside the function:
  model.fit(data[predictors],data[outcome]) 
import random
random.seed(1)
model = DecisionTreeClassifier()
outcome_var = 'Loan_Status'
predictor_var = ['Credit_History','Education','Married','Self_Employed','Property_Area']
classification_model(model, df,predictor_var,outcome_var)
#We can try different combination of variables:
predictor_var = ['Credit_History','Gender','Married','Education']
classification_model(model, df,predictor_var,outcome_var)
model = LogisticRegression()
predictor_var = ['Credit_History']
classification_model(model, df,predictor_var,outcome_var)
df_test = pd.read_csv("data/test_LoanPredDataset.csv") 

df_test['Self_Employed'].fillna('No',inplace=True)
df_test['LoanAmount'].fillna(df_test[df_test['LoanAmount'].isnull()].apply(fage, axis=1), 
                        inplace=True)
df_test['LoanAmount_log'] = np.log(df_test['LoanAmount'])
df_test['TotalIncome'] = df_test['ApplicantIncome'] + df_test['CoapplicantIncome']
df_test['TotalIncome_log'] = np.log(df_test['TotalIncome'])
df_test['Gender'].fillna('Male',inplace=True)
df_test['Married'].fillna('Yes',inplace=True)
df_test['Dependents'].fillna('0',inplace=True)
df_test['Loan_Amount_Term'].fillna(df_test['Loan_Amount_Term'].mean()
                              ,inplace=True)
df_test['Credit_History'].fillna(1.0,inplace=True)
var_mod = ['Gender','Married','Dependents','Education',
           'Self_Employed','Property_Area', 'Loan_Status']
#df_test.Loan_Status
for i in var_mod:
    df_test[i] = le.fit_transform(df_test[i])
model = LogisticRegression()
predictor_var = ['Credit_History']
model.fit(df[predictor_var],df[outcome_var])
predictions = model.predict(df_test[predictor_var])
predictions
df_test.shape
#df_test.Loan_Status
#Print test accuracy
test_accuracy = metrics.accuracy_score(predictions,df_test[outcome_var])
print("Test Data Accuracy : %s" % "{0:.3%}".format(test_accuracy)) 


